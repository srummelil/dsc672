{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from pandas import Series\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    " \n",
    "production=pd.read_pickle(\"./processed/production_all_dates_and_variables.pkl\")\n",
    "keep_these=['Wind_KWH',\n",
    "            'Solar_KWH',\n",
    "            'Wind_Speed_AT_WINDFARM',\n",
    "            'Solar_Elevation',\n",
    "            'Cloud_Cover_Fraction',\n",
    "            'Dew_Point',\n",
    "            'Humidity_Fraction',\n",
    "            'Precipitation',\n",
    "            'Pressure',\n",
    "            'Temperature',\n",
    "            'Visibility',\n",
    "            'Wind_Speed_AT_SOLARRAY']\n",
    "production=production[keep_these]\n",
    "#fill the date and time gaps\n",
    "production = production.resample(\"60min\").asfreq()\n",
    "production.to_pickle(\"./processed/production_full_date_range_pre_impute.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Solar_KWH  Cloud_Cover_Fraction  Dew_Point  Humidity_Fraction  \\\n",
      "Date                                                                            \n",
      "2010-01-04   20084.160000              1.000000  -8.300000           0.698400   \n",
      "2010-01-05  111402.100000              1.000000  -7.000000           0.789400   \n",
      "2010-01-06  163901.380000              1.000000  -6.950000           0.768500   \n",
      "2010-01-07   95813.460000              0.985714  -6.442857           0.865729   \n",
      "2010-01-08  116167.524153              0.987500 -11.062500           0.723737   \n",
      "\n",
      "            Precipitation    Pressure  Temperature  Visibility  \\\n",
      "Date                                                             \n",
      "2010-01-04       0.000000  992.050049    -3.600000   16.093000   \n",
      "2010-01-05       0.000000  992.112488    -3.875000   15.087251   \n",
      "2010-01-06       0.000000  993.799988    -3.475000   16.093000   \n",
      "2010-01-07       0.071429  991.649963    -4.528572   11.954858   \n",
      "2010-01-08       0.000000  996.012512    -6.937500   15.288500   \n",
      "\n",
      "            Wind_Speed_AT_SOLARRAY  \n",
      "Date                                \n",
      "2010-01-04                4.650000  \n",
      "2010-01-05                4.250000  \n",
      "2010-01-06                3.475000  \n",
      "2010-01-07                1.271428  \n",
      "2010-01-08                5.212500  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement an imputation scheme for each variable.\n",
    "\n",
    "\n",
    "Dependent Variables - no imputation\n",
    "solar - if nighttime, zero\n",
    "wind - ???\n",
    "=========================================\n",
    "'Wind_KWH',\n",
    "'Solar_KWH',\n",
    "\n",
    "Dependent Variables - impute as described\n",
    "CHECK SPARSITY OF VALUES PRIOR TO IMPUTING\n",
    "=========================================\n",
    "'Wind_Speed_AT_WINDFARM', - high variance, \n",
    "'Solar_Elevation', # Removing, as there is no good way to aggregate this by day, nor is it necessarily relevant except\n",
    "                     as a performance measure of the solar array, which is not under analysis.\n",
    "'Cloud_Cover_Fraction', - Average\n",
    "'Dew_Point', - Average\n",
    "'Humidity_Fraction', - Average\n",
    "'Precipitation', - Average\n",
    "'Pressure', - Average\n",
    "'Temperature', - Average\n",
    "'Visibility', - Average\n",
    "'Wind_Speed_AT_SOLARRAY' - Average\n",
    "\n",
    "Note: We should do inter-day analysis as well, if possible.\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# Create dataset for seasonality of solar KWH by day.\n",
    "\n",
    "solar_prod=production['Solar_KWH']\n",
    "solar_prod_by_day = solar_prod.resample(\"D\").sum().to_frame('Solar_KWH')\n",
    "solar_prod_by_day.to_pickle(\"./processed/solar_prod_by_day.pkl\")\n",
    "\n",
    "independent_vars=['Cloud_Cover_Fraction',\n",
    "                  'Dew_Point',\n",
    "                  'Humidity_Fraction',\n",
    "                  'Precipitation',\n",
    "                  'Pressure',\n",
    "                  'Temperature',\n",
    "                  'Visibility',\n",
    "                  'Wind_Speed_AT_SOLARRAY']\n",
    "\n",
    "indep_vars=production[independent_vars]\n",
    "for field in independent_vars:\n",
    "    # consumption_master = consumption_master.join(calendar, how='outer', sort=True)\n",
    "    # For each field, aggregate by day, then join to solar_prod\n",
    "    tmp=pd.DataFrame(data=indep_vars[field])\n",
    "    tmp.dropna(axis=0, inplace=True)\n",
    "    tmp=tmp.loc[tmp[field]!='nan'] # How we got text 'nan' in here, I do not know, but remove them.\n",
    "    tmp=pd.to_numeric(tmp[field], downcast='float')\n",
    "    # Averaging the remaining values by day should yield a useful metric for modeling, even if\n",
    "    # it would be meaningless from a real weather-reporting context. \n",
    "    # We are imposing the same limitation on all variables, so should still be representative.\n",
    "    tmp=tmp.resample(\"D\").mean().to_frame(field)\n",
    "    #print(tmp.head())\n",
    "    solar_prod_by_day=solar_prod_by_day.join(tmp, how='left', sort=True)\n",
    "    \n",
    "#print(solar_prod_by_day.head())\n",
    "\n",
    "\n",
    "# Now, we need to interpolate missing values.\n",
    "\n",
    "def interpolate_gaps(values, limit=None):\n",
    "    \"\"\"\n",
    "    Fill gaps using linear interpolation, optionally only fill gaps up to a\n",
    "    size of `limit`, courtesy of StackOVerflow:\n",
    "    https://stackoverflow.com/questions/36455083/working-with-nan-values-in-matplotlib\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    i = np.arange(values.size)\n",
    "    valid = np.isfinite(values)\n",
    "    filled = np.interp(i, i[valid], values[valid])\n",
    "\n",
    "    if limit is not None:\n",
    "        invalid = ~valid\n",
    "        for n in range(1, limit+1):\n",
    "            invalid[:-n] &= invalid[n:]\n",
    "        filled[invalid] = np.nan\n",
    "    return filled\n",
    "\n",
    "\n",
    "columns={}\n",
    "dates=solar_prod_by_day.index.values\n",
    "columns['Date']=dates\n",
    "for field in list(solar_prod_by_day):\n",
    "    raw=solar_prod_by_day[field].values\n",
    "    filled = interpolate_gaps(raw, limit=2)\n",
    "    columns[field]=filled\n",
    "\n",
    "solar_prod_by_day_fnl=pd.DataFrame.from_dict(columns)\n",
    "solar_prod_by_day_fnl.set_index('Date', inplace=True)\n",
    "solar_prod_by_day_fnl.to_pickle(\"./processed/solar_prod_by_day_w_interpolation.pkl\")\n",
    "print(solar_prod_by_day_fnl.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Test: [2010] Train: [2011, 2012, 2013]\n",
      "ARIMA(0, 0, 0)x(0, 0, 0, 365) - AIC:37693.76839351221 - best AIC: 37693.76839351221 - Iteration: 2\n",
      "ARIMA(0, 0, 0)x(0, 0, 1, 365) - AIC:nan - best AIC: 37693.76839351221 - Iteration: 3\n",
      "Exception: maxlag should be < nobs ARIMA(0, 0, 0)x(0, 0, 2, 365)12 - Iteration: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e0bd70d44b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m                                                                   \u001b[0msolar_prod_by_day_fnl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                                                   \u001b[0mexogenous_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                                                                   'Solar_KWH')\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     print(\"Best param: {} Best Seasonal Param: {} best AIC: {}\".format(tmp_best_param,\n",
      "\u001b[0;32m<ipython-input-3-8e0bd70d44b8>\u001b[0m in \u001b[0;36mfind_best_model\u001b[0;34m(train_years, test_years, df, exogenous_variables, endogenous_variable)\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                 enforce_invertibility=False)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mtmp_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, transformed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             res = self.smooth(mlefit.params, transformed=False,\n\u001b[0;32m--> 477\u001b[0;31m                               cov_type=cov_type, cov_kwds=cov_kwds)\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36msmooth\u001b[0;34m(self, params, transformed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m         return self._wrap_results(params, result, return_ssm, cov_type,\n\u001b[1;32m    597\u001b[0m                                   \u001b[0mcov_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                                   results_wrapper_class)\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0m_loglike_param_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'transformed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'complex_step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_wrap_results\u001b[0;34m(self, params, result, return_raw, cov_type, cov_kwds, results_class, wrapper_class)\u001b[0m\n\u001b[1;32m    502\u001b[0m                 \u001b[0mwrapper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_res_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mresult_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, params, filter_results, cov_type, **kwargs)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                  **kwargs):\n\u001b[1;32m   1726\u001b[0m         super(SARIMAXResults, self).__init__(model, params, filter_results,\n\u001b[0;32m-> 1727\u001b[0;31m                                              cov_type, **kwargs)\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_resid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m  \u001b[0;31m# attribute required for wald tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, params, results, cov_type, cov_kwds, **kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m             self._get_robustcov_results(cov_type=cov_type, use_self=True,\n\u001b[0;32m-> 1577\u001b[0;31m                                         **cov_kwds)\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_get_robustcov_results\u001b[0;34m(self, cov_type, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m                 ' matrix (%s) described in Harvey (1989).' % approx_type_str)\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'opg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_params_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_params_opg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m             res.cov_kwds['description'] = (\n\u001b[1;32m   1705\u001b[0m                 \u001b[0;34m'Covariance matrix calculated using the outer product of'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tools/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cachedval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Call the \"fget\" function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0m_cachedval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;31m# Set the attribute in obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# print(\"Setting %s in cache to %s\" % (name, _cachedval))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mcov_params_opg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \"\"\"\n\u001b[1;32m   1816\u001b[0m         return self._cov_params_opg(self._cov_approx_complex_step,\n\u001b[0;32m-> 1817\u001b[0;31m                                     self._cov_approx_centered)\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_cov_params_opg\u001b[0;34m(self, approx_complex_step, approx_centered)\u001b[0m\n\u001b[1;32m   1799\u001b[0m                                         \u001b[0mtransformed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m                                         \u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1801\u001b[0;31m                                         approx_centered=approx_centered)\n\u001b[0m\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mneg_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingular_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinv_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_hessian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_hessian_opg\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0minformation\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \"\"\"\n\u001b[0;32m-> 1228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopg_information_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m     def _hessian_finite_difference(self, params, approx_centered=False,\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mopg_information_matrix\u001b[0;34m(self, params, transformed, approx_complex_step, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m         score_obs = self.score_obs(params, transformed=transformed,\n\u001b[1;32m    930\u001b[0m                                    \u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                                    **kwargs).transpose()\n\u001b[0m\u001b[1;32m    932\u001b[0m         return (\n\u001b[1;32m    933\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_obs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mscore_obs\u001b[0;34m(self, params, method, transformed, approx_complex_step, approx_centered, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transformed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             score = approx_fprime_cs(params, self.loglikeobs, epsilon=epsilon,\n\u001b[0;32m-> 1134\u001b[0;31m                                      kwargs=kwargs)\n\u001b[0m\u001b[1;32m   1135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'approx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transformed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tools/numdiff.py\u001b[0m in \u001b[0;36mapprox_fprime_cs\u001b[0;34m(x, f, epsilon, args, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# TODO: see if this can be vectorized, but usually dim is small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     partials = [f(x+ih, *args, **kwargs).imag / epsilon[i]\n\u001b[0;32m--> 202\u001b[0;31m                 for i, ih in enumerate(increments)]\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tools/numdiff.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# TODO: see if this can be vectorized, but usually dim is small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     partials = [f(x+ih, *args, **kwargs).imag / epsilon[i]\n\u001b[0;32m--> 202\u001b[0;31m                 for i, ih in enumerate(increments)]\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mloglikeobs\u001b[0;34m(self, params, transformed, complex_step, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikeobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimulation_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulation_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36mloglikeobs\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m                                ' MEMORY_NO_LIKELIHOOD option is selected.')\n\u001b[1;32m    854\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conserve_memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMEMORY_CONSERVE\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mMEMORY_NO_LIKELIHOOD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0mkfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mllf_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/csc481/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36m_filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# Run the filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mkfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# From: \n",
    "# https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3\n",
    "# Significantly adapted, but the iterative approach and some code is a direct-use.\n",
    "\n",
    "def find_best_model(train_years, test_years, df, exogenous_variables, endogenous_variable):\n",
    "    train_data=df[endogenous_variable].loc[(df.index.year.isin(train_years))]\n",
    "    exog=df[exogenous_variables].loc[(df.index.year.isin(train_years))].values\n",
    "    train=train_data.values\n",
    "\n",
    "    test_data=df[endogenous_variable].loc[(df.index.year.isin(test_years))]\n",
    "    test=test_data.values\n",
    "\n",
    "    # Define the p, d and q parameters to take any value between 0 and 2\n",
    "    p = d = q = range(0, 3)\n",
    "\n",
    "    # Generate all different combinations of p, q and q triplets\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "    # Generate all different combinations of seasonal p, q and q triplets\n",
    "    # Since we are daily data, m=360, suggesting a yearly cycle.\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], 360) for x in list(itertools.product(p, d, q))]\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "    count=1\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(train,\n",
    "                                                exog=exog,\n",
    "                                                order=param,\n",
    "                                                seasonal_order=param_seasonal,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "\n",
    "                results = mod.fit()\n",
    "                if count==1:\n",
    "                    tmp_best=results.aic\n",
    "                    count+=1\n",
    "                else:\n",
    "                    if tmp_best > results.aic:\n",
    "                        tmp_best=results.aic\n",
    "                        tmp_best_param=param\n",
    "                        tmp_best_seasonal=param_seasonal\n",
    "                        count+=1\n",
    "                    else:\n",
    "                        count+=1\n",
    "                    \n",
    "                print('ARIMA{}x{} - AIC:{} - best AIC: {} - Iteration: {}'.format(param,\n",
    "                                                                                    param_seasonal,\n",
    "                                                                                    results.aic,\n",
    "                                                                                    tmp_best,\n",
    "                                                                                    count))\n",
    "            \n",
    "            except Exception as e:\n",
    "                print('Exception: {} ARIMA{}x{} - Iteration: {}'.format(e,\n",
    "                                                                          param,\n",
    "                                                                          param_seasonal,\n",
    "                                                                          count))\n",
    "                continue\n",
    "                \n",
    "    return(tmp_best, tmp_best_param, tmp_best_seasonal)\n",
    "\n",
    "\n",
    "# Lets split the data into 3 years train, one test, across years. Assumption: That any long-\n",
    "# term weather trend will not manifest materially within a three year timeframe.\n",
    "\n",
    "years=[2010, 2011, 2012, 2013]\n",
    "\n",
    "# Keep: Visibility, Temperature, and Pressure - Pressure has NaN, dropping it.\n",
    "exogenous_variables=['Visibility', 'Temperature']\n",
    "\n",
    "#for scenario in scenarios:\n",
    "for iteration in range(0, len(years)):\n",
    "    list_len=len(years)\n",
    "    train_years=years[1:len(years)]\n",
    "    test_year=[]\n",
    "    test_year.append(years[0])\n",
    "    print(\"Iteration: {} Test: {} Train: {}\".format(iteration, test_year, train_years))\n",
    "    tmp_best, tmp_best_param, tmp_best_seasonal = find_best_model(train_years,\n",
    "                                                                  test_year,\n",
    "                                                                  solar_prod_by_day_fnl,\n",
    "                                                                  exogenous_variables,\n",
    "                                                                  'Solar_KWH')\n",
    "\n",
    "    print(\"Best param: {} Best Seasonal Param: {} best AIC: {}\".format(tmp_best_param,\n",
    "                                                                       tmp_best_seasonal,\n",
    "                                                                       tmp_best))\n",
    "    years.append(years.pop(0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(train,\n",
    "                                order=tmp_best_param,\n",
    "                                seasonal_order=tmp_best_seasonal,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "results = mod.fit()\n",
    "\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(15, 12))\n",
    "plt.show()\n",
    "#imgname=\"SARIMA_train_{}_test_{}_param_{}_seasonal_{}\".format(2010, 2013, tmp_best_param, tmp_best_seasonal)\n",
    "#results.plot_diagnostics(figsize=(15, 12)).savefig(\"./Images/\" + imgname + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(solar_prod_by_day_fnl.corr())\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = solar_prod_by_day_fnl.corr()\n",
    "sns.heatmap(corr,\n",
    "            mask=np.zeros_like(corr,\n",
    "                               dtype=np.bool),\n",
    "            cmap=sns.diverging_palette(220,\n",
    "                                       10,\n",
    "                                       as_cmap=True),\n",
    "            square=True, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Visibility, Temperature, and Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our primary concern is to ensure that the residuals of our model are uncorrelated and \n",
    "normally distributed with zero-mean. If the seasonal ARIMA model does not satisfy these properties, \n",
    "it is a good indication that it can be further improved.\n",
    "\n",
    "In this case, our model diagnostics suggests that the model residuals are roughly normally \n",
    "distributed based on the following:\n",
    "\n",
    "In the top right plot, we see that the red KDE line does follows the N(0,1) line, which \n",
    "is the standard notation for a normal distribution with mean 0 and standard deviation of 1), except for a \n",
    "spike between 0 and 1. This is a good indication that the residuals are roughly normally distributed.\n",
    "\n",
    "The qq-plot on the bottom left shows that the ordered distribution of residuals (blue dots)\n",
    "follows the linear trend of the samples taken from a standard normal distribution with N(0, 1).\n",
    "This is a decent indication that the residuals are normally distributed.\n",
    "\n",
    "The residuals over time (top left plot) don't display any obvious seasonality and appear to be white noise.\n",
    "\n",
    "This is confirmed by the autocorrelation (i.e. correlogram) plot on the bottom right,\n",
    "which shows that the time series residuals have low correlation with lagged versions of itself.\n",
    "Those observations lead us to conclude that our model produces a satisfactory fit that could help us\n",
    "understand our time series data and forecast future values.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
