{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pandas import Series\n",
    "from pandas import datetime\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    " \n",
    "production=pd.read_pickle(\"./processed/production_all_dates_and_variables.pkl\")\n",
    "keep_these=['Wind_KWH',\n",
    "            'Solar_KWH',\n",
    "            'Wind_Speed_AT_WINDFARM',\n",
    "            'Solar_Elevation',\n",
    "            'Cloud_Cover_Fraction',\n",
    "            'Dew_Point',\n",
    "            'Humidity_Fraction',\n",
    "            'Precipitation',\n",
    "            'Pressure',\n",
    "            'Temperature',\n",
    "            'Visibility',\n",
    "            'Wind_Speed_AT_SOLARRAY']\n",
    "production=production[keep_these]\n",
    "#fill the date and time gaps\n",
    "production = production.resample(\"60min\").asfreq()\n",
    "production.to_pickle(\"./processed/production_full_date_range_pre_impute.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement an imputation scheme for each variable.\n",
    "\n",
    "\n",
    "Dependent Variables - no imputation\n",
    "solar - if nighttime, zero\n",
    "wind - ???\n",
    "=========================================\n",
    "'Wind_KWH',\n",
    "'Solar_KWH',\n",
    "\n",
    "Dependent Variables - impute as described\n",
    "CHECK SPARSITY OF VALUES PRIOR TO IMPUTING\n",
    "=========================================\n",
    "'Wind_Speed_AT_WINDFARM', - high variance, \n",
    "'Solar_Elevation', # Removing, as there is no good way to aggregate this by day, nor is it necessarily relevant except\n",
    "                     as a performance measure of the solar array, which is not under analysis.\n",
    "'Cloud_Cover_Fraction', - Average\n",
    "'Dew_Point', - Average\n",
    "'Humidity_Fraction', - Average\n",
    "'Precipitation', - Average\n",
    "'Pressure', - Average\n",
    "'Temperature', - Average\n",
    "'Visibility', - Average\n",
    "'Wind_Speed_AT_SOLARRAY' - Average\n",
    "\n",
    "Note: We should do inter-day analysis as well, if possible.\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# Create dataset for seasonality of solar KWH by day.\n",
    "\n",
    "solar_prod=production['Solar_KWH']\n",
    "solar_prod_by_day = solar_prod.resample(\"D\").sum().to_frame('Solar_KWH')\n",
    "solar_prod_by_day.to_pickle(\"./processed/solar_prod_by_day.pkl\")\n",
    "\n",
    "independent_vars=['Cloud_Cover_Fraction',\n",
    "                  'Dew_Point',\n",
    "                  'Humidity_Fraction',\n",
    "                  'Precipitation',\n",
    "                  'Pressure',\n",
    "                  'Temperature',\n",
    "                  'Visibility',\n",
    "                  'Wind_Speed_AT_SOLARRAY']\n",
    "\n",
    "indep_vars=production[independent_vars]\n",
    "for field in independent_vars:\n",
    "    # consumption_master = consumption_master.join(calendar, how='outer', sort=True)\n",
    "    # For each field, aggregate by day, then join to solar_prod\n",
    "    tmp=pd.DataFrame(data=indep_vars[field])\n",
    "    tmp.dropna(axis=0, inplace=True)\n",
    "    tmp=tmp.loc[tmp[field]!='nan'] # How we got text 'nan' in here, I do not know, but remove them.\n",
    "    tmp=pd.to_numeric(tmp[field], downcast='float')\n",
    "    # Averaging the remaining values by day should yield a useful metric for modeling, even if\n",
    "    # it would be meaningless from a real weather-reporting context. \n",
    "    # We are imposing the same limitation on all variables, so should still be representative.\n",
    "    tmp=tmp.resample(\"D\").mean().to_frame(field)\n",
    "    #print(tmp.head())\n",
    "    solar_prod_by_day=solar_prod_by_day.join(tmp, how='left', sort=True)\n",
    "    \n",
    "#print(solar_prod_by_day.head())\n",
    "\n",
    "\n",
    "# Now, we need to interpolate missing values.\n",
    "\n",
    "def interpolate_gaps(values, limit=None):\n",
    "    \"\"\"\n",
    "    Fill gaps using linear interpolation, optionally only fill gaps up to a\n",
    "    size of `limit`, courtesy of StackOVerflow:\n",
    "    https://stackoverflow.com/questions/36455083/working-with-nan-values-in-matplotlib\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    i = np.arange(values.size)\n",
    "    valid = np.isfinite(values)\n",
    "    filled = np.interp(i, i[valid], values[valid])\n",
    "\n",
    "    if limit is not None:\n",
    "        invalid = ~valid\n",
    "        for n in range(1, limit+1):\n",
    "            invalid[:-n] &= invalid[n:]\n",
    "        filled[invalid] = np.nan\n",
    "    return filled\n",
    "\n",
    "\n",
    "columns={}\n",
    "dates=solar_prod_by_day.index.values\n",
    "columns['Date']=dates\n",
    "for field in list(solar_prod_by_day):\n",
    "    raw=solar_prod_by_day[field].values\n",
    "    filled = interpolate_gaps(raw, limit=2)\n",
    "    columns[field]=filled\n",
    "\n",
    "solar_prod_by_day_fnl=pd.DataFrame.from_dict(columns)\n",
    "solar_prod_by_day_fnl.set_index('Date', inplace=True)\n",
    "solar_prod_by_day_fnl.to_pickle(\"./processed/solar_prod_by_day_w_interpolation.pkl\")\n",
    "print(solar_prod_by_day_fnl.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "import statsmodels.api as sm\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.style.use('fivethirtyeight')\n",
    "\n",
    "# From: \n",
    "# https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3\n",
    "\n",
    "# Lets split the data into 3 years train, one test, across years. Assumption: That any long-\n",
    "# term weather trend will not manifest materially within a three year timeframe.\n",
    "\n",
    "# First Run\n",
    "#train_years=[2010, 2011, 2012]\n",
    "#test_years=[2013]\n",
    "\n",
    "# Second Run\n",
    "#train_years=[2011, 2012, 2013]\n",
    "#test_years=[2010]\n",
    "\n",
    "# Third Run\n",
    "#train_years=[2012, 2013, 2010]\n",
    "#test_years=[2011]\n",
    "\n",
    "# Fourth Run\n",
    "train_years=[2013, 2010, 2011]\n",
    "test_years=[2012]\n",
    "\n",
    "# Keep: Visibility, Temperature, and Pressure - Pressure has NaN, need to deal with that.\n",
    "exogenous_variables=['Visibility', 'Temperature']\n",
    "\n",
    "train_data=solar_prod_by_day_fnl['Solar_KWH'].loc[(solar_prod_by_day_fnl.index.year.isin(train_years))]\n",
    "exog=solar_prod_by_day_fnl[exogenous_variables].loc[(solar_prod_by_day_fnl.index.year.isin(train_years))].values\n",
    "train=train_data.values\n",
    "\n",
    "test_data=solar_prod_by_day_fnl['Solar_KWH'].loc[(solar_prod_by_day_fnl.index.year.isin(test_years))]\n",
    "test=test_data.values\n",
    "\n",
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0, 3)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], len(train)) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "count=1\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(train,\n",
    "                                            exog=exog,\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            results = mod.fit()\n",
    "            if count==1:\n",
    "                tmp_best=results.aic\n",
    "                count+=1\n",
    "            else:\n",
    "                if tmp_best > results.aic:\n",
    "                    tmp_best=results.aic\n",
    "                    tmp_best_param=param\n",
    "                    tmp_best_seasonal=param_seasonal\n",
    "                    count+=1\n",
    "                else:\n",
    "                    count+=1\n",
    "                    \n",
    "            print('ARIMA{}x{}12 - AIC:{} - best AIC: {} - Iteration: {}'.format(param,\n",
    "                                                                                param_seasonal,\n",
    "                                                                                results.aic,\n",
    "                                                                                tmp_best,\n",
    "                                                                                count))\n",
    "            \n",
    "        except:\n",
    "            print(\"Exception!\")\n",
    "            continue\n",
    "\n",
    "print(\"Best param: {} Best Seasonal Param: {} best AIC: {}\".format(tmp_best_param,\n",
    "                                                                   tmp_best_seasonal,\n",
    "                                                                   tmp_best))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth Run\n",
    "train_years=[2013, 2010, 2011]\n",
    "test_years=[2012]\n",
    "\n",
    "# Keep: Visibility, Temperature, and Pressure\n",
    "exogenous_variables=['Visibility', 'Temperature']\n",
    "\n",
    "train_data=solar_prod_by_day_fnl['Solar_KWH'].loc[(solar_prod_by_day_fnl.index.year.isin(train_years))]\n",
    "exog=solar_prod_by_day_fnl[exogenous_variables].loc[(solar_prod_by_day_fnl.index.year.isin(train_years))].values\n",
    "train=train_data.values\n",
    "\n",
    "test_data=solar_prod_by_day_fnl['Solar_KWH'].loc[(solar_prod_by_day_fnl.index.year.isin(test_years))]\n",
    "test=test_data.values\n",
    "\n",
    "#print(exog)\n",
    "\n",
    "# TMP Vals\n",
    "pdq = (1, 1, 1)\n",
    "\n",
    "# TMP vals for testing\n",
    "seasonal_pdq = (0, 0, 0, len(train))\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "mod = sm.tsa.statespace.SARIMAX(train,\n",
    "                                exog=exog,\n",
    "                                order=pdq,\n",
    "                                seasonal_order=seasonal_pdq,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "results = mod.fit()\n",
    "tmp_best=results.aic\n",
    "tmp_best_param=pdq\n",
    "tmp_best_seasonal=seasonal_pdq\n",
    "print(\"Best param: {} Best Seasonal Param: {} best AIC: {}\".format(tmp_best_param,\n",
    "                                                                   tmp_best_seasonal,\n",
    "                                                                   tmp_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(train,\n",
    "                                order=tmp_best_param,\n",
    "                                seasonal_order=tmp_best_seasonal,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "results = mod.fit()\n",
    "\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(15, 12))\n",
    "plt.show()\n",
    "#imgname=\"SARIMA_train_{}_test_{}_param_{}_seasonal_{}\".format(2010, 2013, tmp_best_param, tmp_best_seasonal)\n",
    "#results.plot_diagnostics(figsize=(15, 12)).savefig(\"./Images/\" + imgname + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(solar_prod_by_day_fnl.corr())\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = solar_prod_by_day_fnl.corr()\n",
    "sns.heatmap(corr,\n",
    "            mask=np.zeros_like(corr,\n",
    "                               dtype=np.bool),\n",
    "            cmap=sns.diverging_palette(220,\n",
    "                                       10,\n",
    "                                       as_cmap=True),\n",
    "            square=True, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Visibility, Temperature, and Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our primary concern is to ensure that the residuals of our model are uncorrelated and \n",
    "normally distributed with zero-mean. If the seasonal ARIMA model does not satisfy these properties, \n",
    "it is a good indication that it can be further improved.\n",
    "\n",
    "In this case, our model diagnostics suggests that the model residuals are roughly normally \n",
    "distributed based on the following:\n",
    "\n",
    "In the top right plot, we see that the red KDE line does follows the N(0,1) line, which \n",
    "is the standard notation for a normal distribution with mean 0 and standard deviation of 1), except for a \n",
    "spike between 0 and 1. This is a good indication that the residuals are roughly normally distributed.\n",
    "\n",
    "The qq-plot on the bottom left shows that the ordered distribution of residuals (blue dots)\n",
    "follows the linear trend of the samples taken from a standard normal distribution with N(0, 1).\n",
    "This is a decent indication that the residuals are normally distributed.\n",
    "\n",
    "The residuals over time (top left plot) don't display any obvious seasonality and appear to be white noise.\n",
    "\n",
    "This is confirmed by the autocorrelation (i.e. correlogram) plot on the bottom right,\n",
    "which shows that the time series residuals have low correlation with lagged versions of itself.\n",
    "Those observations lead us to conclude that our model produces a satisfactory fit that could help us\n",
    "understand our time series data and forecast future values.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
